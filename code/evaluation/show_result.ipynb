{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb94ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_accuracy_per_file(input_data):\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for item in input_data:\n",
    "        true_label = str(item.get(\"True Label\")).strip()\n",
    "        model_answer = str(item.get(\"model_answer_number\")).strip()\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(model_answer)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    correct = sum([yt == yp for yt, yp in zip(y_true, y_pred)])\n",
    "    total = len(y_true)\n",
    "    summary = {\n",
    "        \"accuracy\": round(acc * 100, 2),\n",
    "        \"correct\": correct,\n",
    "        \"total\": total\n",
    "    }\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990b9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "folder_name = \"['no_context']\"\n",
    "folder_name = \"['birth']\"\n",
    "folder_name = \"['Nationality']\"\n",
    "folder_name = \"['Summary']\"\n",
    "folder_name = \"['birth', 'Nationality']\"\n",
    "folder_name = \"['birth', 'Summary']\"\n",
    "folder_name = \"['Nationality', 'Summary']\"\n",
    "folder_name = \"['birth', 'Nationality', 'Summary']\"\n",
    "\n",
    "\n",
    "# \"EXAONE-3.5-7.8B-Instruct\"\n",
    "# \"EXAONE-3.0-7.8B-Instruct\"\n",
    "# \"Llama-3.1-8B-Instruct\"\n",
    "# \"Mistral-Nemo-Instruct-2407\"\n",
    "# \"gpt-4o\"\n",
    "# \"gpt-3.5-turbo-0125\"\n",
    "model_name = \"EXAONE-3.5-7.8B-Instruct\"\n",
    "mode = \"version3\"\n",
    "base_path = Path('../../data/prediction_data/gpt-4o') / folder_name\n",
    "base_path = Path(f'../../data/prediction_data/{model_name}_test_data_sample_{mode}') / folder_name\n",
    "base_path = Path(f'../../data/prediction_data/{model_name}_test_data_fin_korea') / folder_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a25cc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(folder_name):\n",
    "    # JSON 파일 이름에서 특정 키워드 추출\n",
    "    keywords = []\n",
    "    pattern = re.compile(r'(cultural|cross|fact|temporal)')\n",
    "\n",
    "    data_dict = {}\n",
    "    for json_file in folder_name.glob('*.json'):\n",
    "        match = pattern.search(json_file.name)\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            data_dict[match.group(1)] = data\n",
    "\n",
    "    character_info = pd.read_json('../../data/source_data/meta_character.json')\n",
    "\n",
    "    character_info = character_info.reset_index().melt(\n",
    "        id_vars='index',\n",
    "        value_vars=['china', 'en', 'korea', 'mexico', 'spain'],\n",
    "        var_name='country',\n",
    "        value_name='info'\n",
    "    ).dropna(subset=['info']).rename(columns={'index': 'character'}).reset_index(drop=True)\n",
    "\n",
    "    character_info_expanded = pd.concat(\n",
    "        [character_info.drop(columns=['info']), character_info['info'].apply(pd.Series)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    for question_type in data_dict:\n",
    "        result_dict[question_type] = {}\n",
    "\n",
    "        for country in data_dict[question_type]:\n",
    "            result_dict[question_type][country] = {}\n",
    "            for character in data_dict[question_type][country]:\n",
    "                result_dict[question_type][country][character] = compute_accuracy_per_file(data_dict[question_type][country][character])\n",
    "\n",
    "    # 정확도 계산 (기존 코드와 동일)\n",
    "    average_accuracies = {}\n",
    "    for q_type, countries in result_dict.items():\n",
    "        average_accuracies[q_type] = {}\n",
    "        for country, characters in countries.items():\n",
    "            accuracies = [char_data['accuracy'] for char_data in characters.values()]\n",
    "            avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0\n",
    "            average_accuracies[q_type][country] = round(avg_accuracy, 2)\n",
    "\n",
    "    df = pd.DataFrame(average_accuracies).T\n",
    "    df['Average'] = df.mean(axis=1).round(2)\n",
    "    df.loc['Average'] = df.mean(axis=0).round(2)\n",
    "\n",
    "    result_df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            (q_type, country): characters\n",
    "            for q_type, countries in result_dict.items()\n",
    "            for country, characters in countries.items()\n",
    "        },\n",
    "        orient='index'\n",
    "    )\n",
    "\n",
    "    result_df.index.names = ['Question Type', 'Country']\n",
    "\n",
    "    result_df_reset = result_df.reset_index().melt(\n",
    "        id_vars=['Question Type', 'Country'],\n",
    "        var_name='character_name',\n",
    "        value_name='accuracy_info'\n",
    "    ).dropna(subset=['accuracy_info'])\n",
    "\n",
    "\n",
    "    df = result_df_reset.copy()\n",
    "    df[['accuracy', 'total']] = df['accuracy_info'].apply(pd.Series)[['accuracy', 'total']]\n",
    "\n",
    "\n",
    "    agg = (\n",
    "        df\n",
    "        .groupby(['character_name', 'Question Type'])\n",
    "        .agg(accuracy=('accuracy', 'mean'),\n",
    "            total   =('total',    'sum'))\n",
    "        .unstack('Question Type')   # Question Type을 컬럼으로 펼치기\n",
    "    )\n",
    "\n",
    "    new_cols = []\n",
    "    for metric, qtype in agg.columns:\n",
    "        if metric == 'accuracy':\n",
    "            new_cols.append(f\"{qtype}_accuracy\")\n",
    "        else:  # total\n",
    "            new_cols.append(f\"{qtype}_num\")\n",
    "    agg.columns = new_cols\n",
    "\n",
    "    result = agg.reset_index()\n",
    "\n",
    "    cols_to_check = [col for col in result.columns\n",
    "                    if ('cross' not in col) and ('temporal' not in col)]\n",
    "\n",
    "    filtered_result = result.dropna(subset=cols_to_check)\n",
    "    info_cols = ['character', 'country', 'history', 'time']\n",
    "\n",
    "\n",
    "    merged_df = (\n",
    "        filtered_result\n",
    "        .merge(\n",
    "            character_info_expanded[info_cols],\n",
    "            left_on='character_name',\n",
    "            right_on='character',\n",
    "            how='left'\n",
    "        )\n",
    "        .drop(columns='character')  # 중복된 key 컬럼 제거\n",
    "    )\n",
    "\n",
    "    cols_to_nan = [col for col in merged_df.columns if 'cross' in col or 'temporal' in col]\n",
    "    merged_df.loc[merged_df['time'] == 'present', cols_to_nan] = np.nan\n",
    "\n",
    "    groupings = {\n",
    "        'Country': ['country'],\n",
    "        'History': ['history'],\n",
    "        'Time': ['time'],\n",
    "        'History & Time': ['history', 'time']\n",
    "    }\n",
    "    markdown_lines = []\n",
    "    for name, cols in groupings.items():\n",
    "        # ----- Accuracy Table -----\n",
    "        acc = merged_df.groupby(cols)[[\n",
    "            'cross_accuracy', 'cultural_accuracy',\n",
    "            'fact_accuracy', 'temporal_accuracy'\n",
    "        ]].mean().round(2)\n",
    "        acc['row_avg'] = acc.mean(axis=1).round(2)\n",
    "        acc.loc['col_avg'] = acc.mean().round(2)\n",
    "\n",
    "        markdown_lines.append(f\"### Accuracy by {name}\\n\")\n",
    "        markdown_lines.append(acc.to_markdown())\n",
    "        markdown_lines.append(\"\\n\")\n",
    "\n",
    "        # ----- Num Table -----\n",
    "        nums = merged_df.groupby(cols)[[\n",
    "            'cross_num', 'cultural_num',\n",
    "            'fact_num', 'temporal_num'\n",
    "        ]].sum()\n",
    "        nums['row_sum'] = nums.sum(axis=1)\n",
    "        nums.loc['col_sum'] = nums.sum()\n",
    "\n",
    "        markdown_lines.append(f\"### Num by {name}\\n\")\n",
    "        markdown_lines.append(nums.to_markdown())\n",
    "        markdown_lines.append(\"\\n\")\n",
    "\n",
    "    # result.md 파일로 쓰기\n",
    "    output_path = folder_name / 'result.md'\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(markdown_lines))\n",
    "\n",
    "    print(f\"✅ 마크다운 파일을 생성했습니다: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad3f7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_description = \"test_data_fin_korea\"\n",
    "\n",
    "# \"EXAONE-3.5-7.8B-Instruct\"\n",
    "# \"Qwen3-8B\"\n",
    "# \"Llama-3.1-8B-Instruct\"\n",
    "# \"Mistral-Nemo-Instruct-2407\"\n",
    "# \"gpt-4o\"\n",
    "# \"gpt-3.5-turbo-0125\"\n",
    "model_name = \"EXAONE-3.5-7.8B-Instruct\"\n",
    "input_folder_name = f\"../../data/prediction_data/{model_name}_{input_folder_description}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef1e0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['birth', 'Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['birth']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['birth', 'Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['no_context']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/EXAONE-3.5-7.8B-Instruct_test_data_fin_korea/['birth', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['birth', 'Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['birth']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['birth', 'Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['no_context']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Qwen3-8B_test_data_fin_korea/['birth', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['birth', 'Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['birth']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['birth', 'Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['no_context']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Llama-3.1-8B-Instruct_test_data_fin_korea/['birth', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['birth', 'Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['birth']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['birth', 'Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['no_context']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/Mistral-Nemo-Instruct-2407_test_data_fin_korea/['birth', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['birth', 'Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['birth']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['birth', 'Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['no_context']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-4o_test_data_fin_korea/['birth', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['birth', 'Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['birth']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['birth', 'Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['Nationality', 'Summary']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['Nationality']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['no_context']/result.md\n",
      "✅ 마크다운 파일을 생성했습니다: ../../data/prediction_data/gpt-3.5-turbo-0125_test_data_fin_korea/['birth', 'Summary']/result.md\n"
     ]
    }
   ],
   "source": [
    "model_list = [\"EXAONE-3.5-7.8B-Instruct\", \"Qwen3-8B\", \"Llama-3.1-8B-Instruct\", \"Mistral-Nemo-Instruct-2407\", \"gpt-4o\", \"gpt-3.5-turbo-0125\"]\n",
    "\n",
    "input_folder_description = \"test_data_fin_korea\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "for model_name in model_list:\n",
    "    input_folder_name = f\"../../data/prediction_data/{model_name}_{input_folder_description}\"\n",
    "\n",
    "    folder_paths = [folder for folder in Path(input_folder_name).iterdir() if folder.is_dir()]\n",
    "\n",
    "    for base_path in folder_paths:\n",
    "        make_table(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd814782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81463372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "character_hallucination",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
